{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kkristianr/finetuned_bert_multilingual\")\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"kkristianr/finetuned_bert_multilingual\")\n",
    "model = torch.load('/Users/kristian/dev/dialect_identification/src/finetuned/pytorch_model.bin', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('bs', 0),\n",
    " ('es-AR', 1),\n",
    " ('es-ES', 2),\n",
    " ('es-PE', 3),\n",
    " ('hr', 4),\n",
    " ('pt-BR', 5),\n",
    " ('pt-PT', 6),\n",
    " ('sr', 7),\n",
    " ('BS', 8),\n",
    " ('LU', 9),\n",
    " ('ZH', 10),\n",
    " ('BE', 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 0.1769\n",
      "Class 1: 0.0000\n",
      "Class 2: 0.0000\n",
      "Class 3: 0.0000\n",
      "Class 4: 0.1157\n",
      "Class 5: 0.0000\n",
      "Class 6: 0.0000\n",
      "Class 7: 0.7073\n",
      "Class 8: 0.0000\n",
      "Class 9: 0.0000\n",
      "Class 10: 0.0000\n",
      "Class 11: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"Jelena moze pisati zadacu\"\n",
    "\n",
    "# Tokenize and prepare input for the model\n",
    "inputs = tokenizer(sample_sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "\n",
    "# Get probabilities\n",
    "probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "# Convert probabilities to a list\n",
    "probs_list = probabilities.squeeze().tolist()\n",
    "\n",
    "# Print the probabilities for each class\n",
    "for i, prob in enumerate(probs_list):\n",
    "    print(f\"Class {i}: {prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
